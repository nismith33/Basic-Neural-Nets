{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>The Dataset </b>\n",
        "\n",
        "The [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) consists of 60000 32x32 color images split evenly across 10 different categories:\n",
        "- airplane\n",
        "- automobile\n",
        "- bird\n",
        "- cat\n",
        "- deer\n",
        "- dog\n",
        "- frog\n",
        "- horse\n",
        "- ship\n",
        "- truck\n",
        "\n",
        "The training set has 50000 images, 5000 from each class. The testing data consists of 1000 images from each class. Our goal is to train a neural network to correctly classify images from these 10 types."
      ],
      "metadata": {
        "id": "U72G77AhadZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be using PyTorch to construct our neural net\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "#the CIFAR10 dataset is included in a torchvision module\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "#we can use os to make os-independent file paths to save the model\n",
        "import os"
      ],
      "metadata": {
        "id": "ejnxd7F1aufC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "For computer vision tasks, it is generally a good idea to normalize the images. We will specifically use a normalization\n",
        "method called standardization, in which, for every x in a set, we subtract the mean of the set and divide by the standard\n",
        "deviation. For images, the set we calculate the mean and standard deviation of is the testing data images, and each color\n",
        "channel is standardized seperately. Note this standardization transform must be applied to all other data that goes\n",
        "through the model.\n",
        "\"\"\"\n",
        "#First, we load the training images.\n",
        "image_set = datasets.CIFAR10(root='CIFAR10data', train = True, transform = ToTensor(), download = True)\n",
        "\n",
        "\"\"\"\n",
        "For small datasets, we could just immediately calculate the mean and standard deviation using built in PyTorch methods,\n",
        "but here we will use a more general method that could be used for larger datasets without ever running into memory problems.\n",
        "\"\"\"\n",
        "#We create a DataLoader object for batch processing\n",
        "image_loader = DataLoader(image_set, batch_size = 128)\n",
        "\n",
        "#each channel contains 50000 32x32 images, so total number of pixels (set_size) is:\n",
        "set_size = len(image_set.data )*32*32\n",
        "\n",
        "#We need to loop through the images once to calculate the means for each channel\n",
        "means = torch.zeros(3)\n",
        "for batch, _ in image_loader:\n",
        "    #sum all pixel values in all images of the three color channels, then add them to means\n",
        "    means+=batch.sum([0,2,3])\n",
        "means /= set_size\n",
        "print(f'Means: {means}')\n",
        "\n",
        "#These means can be used to calculate the standard deviations (abbreviated stds)\n",
        "stds = torch.zeros(3)\n",
        "\n",
        "#Makes a tensor of compatible dimension to be broadcast up to the size of each batch for elementwise subtraction in the next loop\n",
        "broadcastable_means = torch.clone(means).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "for batch, _ in image_loader:\n",
        "    #to subtract off means we need to unsqueeze\n",
        "    batch = batch-broadcastable_means\n",
        "    #.mul() is elementwise multiplication, so this is just elementwise squaring\n",
        "    batch = torch.mul(batch,batch)\n",
        "    stds += batch.sum([0,2,3])\n",
        "#now we just divide by the number of elements in each set, and take the square root of each of the three values\n",
        "stds /= set_size\n",
        "stds = torch.sqrt(stds)\n",
        "print(f'Standard Deviations: {stds}')\n"
      ],
      "metadata": {
        "id": "-tM8lSRODVKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we load the testing and training sets, standardizing both of them\n",
        "transform_chain = Compose([ToTensor(), Normalize(means, stds)])\n",
        "\n",
        "training_data = datasets.CIFAR10(root = 'CIFAR10data', train = True, transform = ToTensor(), download = True)\n",
        "testing_data = datasets.CIFAR10(root = 'CIFAR10data', train = False, transform = ToTensor(), download = True)\n",
        "\n",
        "#Next we create DataLoader objects for the data so we can easily process the data in batches.\n",
        "#pin_memory=True speeds the transfer of data from CPU to GPU\n",
        "training_loader = DataLoader(training_data, batch_size = 128, pin_memory=True, shuffle = True)\n",
        "testing_loader = DataLoader(testing_data, batch_size = 128, pin_memory=True, shuffle = False)\n"
      ],
      "metadata": {
        "id": "SMiaL7ZKa8Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Model Architecture </b>\n",
        "\n",
        "For image classification tasks we will use a Convolutional Neural Network. This will make it easier to pick up on features which are characteristic of each image type than if we simply flattened the inputs and used fully-connected layers. Our proposed model has the following layers:\n",
        "\n",
        "1.  - Input Dimension: 3x32x32 (32x32 images with 3 color channels R,G, and B)\n",
        "    - Layer Specifications: convolutional kernel with size 11x11, zero padding of 5 on all sides\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 8x32x32 \n",
        "2.  - Input Dimension: 8x32x32\n",
        "    - Layer Specifications: convolutional kernel with size 7x7, zero padding of 3 on all sides\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 16x32x32\n",
        "3.  - Input Dimension: 16x32x32\n",
        "    - Layer Specifications: convolutional kernel with size 5x5, zero padding of 2 on all sides\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 16x28x28\n",
        "4.  - Input Dimension: 16x32x32\n",
        "    - Layer Specifications: convolutional kernel with size 5x5\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 16x28x28\n",
        "5.  - Input Dimension: 16x28x28\n",
        "    - Layer Specifications: MaxPooling with 2x2 kernel\n",
        "    - Activation Function: N/A\n",
        "    - Output Dimensions: 16x14x14\n",
        "6.  - Input Dimension: 16x14x14\n",
        "    - Layer Specifications: convolutional kernel with size 5x5\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 16x10x10\n",
        "7.  - Input Dimension: 16x10x10\n",
        "    - Layer Specifications: MaxPooling with 2x2 kernel\n",
        "    - Activation Function: N/A\n",
        "    - Output Dimensions: 16x5x5\n",
        "8.  - Input Dimension: 16x5x5\n",
        "    - Layer Specifications: convolutional kernel with size 5x5\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 160x1x1 (Flatten to 1D)\n",
        "9.  - Input Dimension: 160\n",
        "    - Layer Specifications: fully-connected layer\n",
        "    - Activation Function: ReLU\n",
        "    - Output Dimensions: 160\n",
        "10. - Input Dimension: 160\n",
        "    - Layer Specifications: Dropout layer, zeros 50% of nodes during training (to prevent overfitting). This layer does nothing during testing\n",
        "    - Activation Function: N/A\n",
        "    - Output Dimensions: 160\n",
        "11. - Input Dimension: 160\n",
        "    - Layer Specifications: fully-connected layer\n",
        "    - Activation Function: Softmax\n",
        "    - Output Dimensions: 10"
      ],
      "metadata": {
        "id": "7np9OWtIarjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we will define our Neural Network using the architecture described above\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 11, padding = 5)\n",
        "    self.layer2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 7, padding = 3)\n",
        "    self.layer3 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5, padding = 2)\n",
        "    self.layer4 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5)\n",
        "    self.layer5 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.layer6 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5)\n",
        "    self.layer7 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.layer8 = nn.Conv2d(in_channels = 16, out_channels = 160, kernel_size = 5)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.layer9 = nn.Linear(in_features = 160, out_features = 160)\n",
        "    self.layer10 = nn.Dropout(p = 0.5)\n",
        "    self.layer11 = nn.Linear(in_features = 160, out_features = 16)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = nn.functional.relu(self.layer1(x))\n",
        "    x = nn.functional.relu(self.layer2(x))\n",
        "    x = nn.functional.relu(self.layer3(x))\n",
        "    x = nn.functional.relu(self.layer4(x))\n",
        "    x = self.layer5(x)\n",
        "    x = nn.functional.relu(self.layer6(x))\n",
        "    x = self.layer7(x)\n",
        "    x = nn.functional.relu(self.layer8(x))\n",
        "    x = self.flatten(x)\n",
        "    x = nn.functional.relu(self.layer9(x))\n",
        "    x = self.layer10(x)\n",
        "    x = nn.functional.softmax(self.layer11(x), dim = 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "RbJx5XbXjBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a convolutional network with significantly more parameters than the first.\n",
        "class HeavyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(HeavyCNN,self).__init__()\n",
        "    self.layer1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 11, padding = 5)\n",
        "    self.layer2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 7, padding = 3)\n",
        "    self.layer3 = nn.Conv2d(in_channels = 16, out_channels = 128, kernel_size = 5)\n",
        "    self.layer4 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.layer5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 5)\n",
        "    self.layer6 = nn.MaxPool2d(kernel_size = 2)\n",
        "    self.layer7 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 5)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.layer8 = nn.Linear(in_features = 512, out_features = 160)\n",
        "    self.layer9 = nn.Dropout(p = 0.5)\n",
        "    self.layer10 = nn.Linear(in_features = 160, out_features = 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = nn.functional.relu(self.layer1(x))\n",
        "    x = nn.functional.relu(self.layer2(x))\n",
        "    x = nn.functional.relu(self.layer3(x))\n",
        "    x = self.layer4(x)\n",
        "    x = nn.functional.relu(self.layer5(x))\n",
        "    x = self.layer6(x)\n",
        "    x = nn.functional.relu(self.layer7(x))\n",
        "    x = self.flatten(x)\n",
        "    x = nn.functional.relu(self.layer8(x))\n",
        "    x = self.layer9(x)\n",
        "    x = nn.functional.softmax(self.layer10(x), dim = 1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "83ZnNz1gCT1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This loop will be used to actually train the model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    #size will be used later to display progress to the user\n",
        "    size = len(dataloader.dataset)\n",
        "    \n",
        "    #X is a batch of inputs, y are the associated ground-truths\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        #First we push X and y to the GPU (if available)\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        #generate the model's predictions based on input X\n",
        "        predictions = model(X)\n",
        "        #calculate how wrong those predictions are\n",
        "        loss = loss_fn(predictions, y)\n",
        "\n",
        "        #Use backpropagation to tweak the model, hopefully increasing accuracy\n",
        "        #First we want to clear the optimizer for new loop iterations\n",
        "        optimizer.zero_grad()\n",
        "        #Actual backpropagation occurs here\n",
        "        loss.backward()\n",
        "        #Take one step in a direction informed by the partial derivatives calculated in the backpropagation\n",
        "        optimizer.step()\n",
        "\n",
        "        #Show the user the model's progress\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    #do not need to calculate the gradient when testing since we will not update model parameters here\n",
        "    with torch.no_grad():\n",
        "        #X is a batch of input data, y is the corresponding ground-truths\n",
        "        for X, y in dataloader:\n",
        "            #first we push X and y to GPU\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            #calculate the models predicted outputs\n",
        "            predictions = model(X)\n",
        "            #calculate the loss generated by predictions and add it to test_loss\n",
        "            test_loss += loss_fn(predictions, y).item()\n",
        "            \n",
        "            \"\"\"\n",
        "            predictions consists of length 10 vectors of percentage values. The value in the\n",
        "            ith position of a prediction is to be roughly interpreted as the confidence that our model\n",
        "            would have classifying the corresponding image as a member of the ith category. For example,\n",
        "            if the seventh component of a prediction is .95, then the model is \"95% confident\" that the \n",
        "            corresponging image is of the seventh type (a frog). So we say the network makes a correct guess\n",
        "            when its highest confidence guess is the correct category.\n",
        "            \"\"\"\n",
        "            correct += (predictions.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    #output information for the user\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "dYkr1Awd0JkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optionally, switch to model=HeavyCNN to use the model with more parameters\n",
        "model = CNN()\n",
        "#determine if there is a GPU available for use\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#if GPU is available, push model to it.\n",
        "model.to(device)\n",
        "learning_rate = .01\n",
        "\n",
        "#cross entropy is a pretty basic loss function choice\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#SGD without momentum was not improving fast enough for my liking. Adagrad uses some second-order\n",
        "#information to rescale the learning rate.\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
        "\n",
        "epochs = 50\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(training_loader, model, loss_fn, optimizer, device)\n",
        "    test_loop(testing_loader, model, loss_fn, device)\n",
        "print(\"Done!\")\n",
        "#This saves the model for later use\n",
        "save_path = os.path.join(os.path.curdir, 'CIFAR10classifier.pt')\n",
        "torch.save(model, save_path)"
      ],
      "metadata": {
        "id": "nSQ3mpnACjt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**\n",
        "\n",
        "Neither network architecture performs spectacularly (CNN averages about 50% accuracy, HeavyCNN averages about 57%), however this is not a problem, as optimization of performance was not the goal; the goal was to figure out the basics of PyTorch. I would consider that goal achieved, and feel far more confident now moving onto harder tasks."
      ],
      "metadata": {
        "id": "Zve4jkKiKP7n"
      }
    }
  ]
}
